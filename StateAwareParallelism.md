# OP_NET Transaction Processing Optimization: **State-Aware Parallelism**

## Navigation

- [Managing Storage Slots in Smart Contracts](#managing-storage-slots-in-smart-contracts-a-brief-introduction)
- [Sequential Transaction Processing and Its Impact](#sequential-transaction-processing-and-its-impact-with-increasing-transaction-flux)
  - [Why Sequential Processing Becomes a Problem](#why-sequential-transaction-processing-becomes-a-problem)
  - [Ethereum vs. Bitcoin Block Size and Transaction Limits](#ethereum-vs-bitcoin-block-size-and-transaction-limits)
  - [Example (Fractal): Sequential Processing Challenges](#example-fractal-sequential-processing-challenges-in-high-throughput-chains)
  - [Comparative Analysis](#comparative-analysis)
  - [Why Sequential Processing Fails](#why-sequential-processing-fails-as-transaction-flux-increases)
- [How State-Aware Parallelism Works](#how-it-works)
  - [Handling Transaction Reverts Due to Missing State](#handling-transaction-reverts-due-to-missing-state)
  - [Optimizing Compute with Promises and Context Blocking](#optimizing-compute-with-promises-and-context-blocking)
- [Why It Works Like This](#why-it-works-like-this)
- [Benefits of State-Aware Parallelism](#benefits-of-this-approach)
- [Challenges](#challenges)
- [Conclusion](#conclusion)

---

## Managing Storage Slots in Smart Contracts: A Brief Introduction

In smart contracts, storage slots are fundamental to how data is stored on-chain. Each contract has a unique storage space on the blockchain, where variables and state data are stored in a key-value mapping, typically referred to as **storage slots**. These slots are structured in a way that allows efficient retrieval and updates of state, which is critical for the correct functioning of smart contracts. You could see this as the RAM (Random Access Memory) of the blockchain.

---

## Sequential Transaction Processing and Its Impact with Increasing Transaction Flux

### Why Sequential Transaction Processing Becomes a Problem

When a blockchain runs transactions **one by one**, it processes them in a strictly sequential manner. As the number of transactions (transaction flux) increases, the system must handle more transactions in a limited timeframe. Sequential processing introduces several key issues:

1. **Latency**: As transaction volume grows, the blockchain must process each transaction individually, leading to longer delays between when a transaction is submitted and when it is confirmed. This results in a **backlog** of unprocessed transactions, causing users to wait longer for confirmations.

2. **Scalability**: Sequential processing limits the blockchainâ€™s ability to scale. With more transactions competing for the same block space, the network may struggle to keep up, making it unable to handle high throughput efficiently.

3. **Resource Utilization**: In sequential processing, CPU and computational resources are underutilized. On modern multicore machines, many CPU cores remain idle while only one core processes a transaction at a time, leading to inefficient resource usage.

---

## Comparative Analysis

This analysis compares **Ethereum** with various blockchains that could theoretically support **OPNet** (Bitcoin, Fractal, Litecoin, Bellcoin). The focus is on the challenges each chain would face when processing compute-heavy OPNet transactions, assuming they take **100ms to 250ms** to compute.

---

## Table 1: Blockchain Comparison - Block Size, Transaction Throughput, and Processing Capacity

| **Blockchain**             | **Block Size**         | **Expected Block Time** | **Expected Transaction Throughput** | **Transaction Flux (Transactions Per Block)** | **Processing Window** | **Theoretical TPS (100ms)** | **Theoretical TPS (250ms)** |
|----------------------------|------------------------|-------------------------|-------------------------------------|-----------------------------------------------|-----------------------|-----------------------------|-----------------------------|
| **Ethereum**                | Variable (Gas limit)   | 12-15 seconds           | ~33-40 TPS                          | ~200-500 transactions                         | 3-10 seconds         | ~33-40 TPS                  | ~13-20 TPS                  |
| **Bitcoin**    | 4 MB (fixed)           | 10 minutes              | ~5-10 TPS                           | ~3,000-5,000 transactions                    | 600 seconds           | ~5-10 TPS                   | ~2-4 TPS                    |
| **Fractal**    | Variable (3,000 txs)   | 30 seconds              | ~100 TPS                            | ~3,000 transactions                          | 30 seconds            | ~100 TPS                    | ~40 TPS                     |
| **Litecoin**   | 4 MB (similar to BTC)  | 2.5 minutes             | ~13 TPS                             | ~2,000 transactions                          | 150 seconds           | ~13 TPS                     | ~8 TPS                      |
| **Bellcoin**   | Variable (3,000 txs)   | 60 seconds              | ~50 TPS                             | ~3,000 transactions                          | 60 seconds            | ~50 TPS                     | ~20 TPS                     |

---

## Table 2: Blockchain Comparison - Processing Time, Congestion Risk, and Scalability Challenges

| **Blockchain**             | **Theoretical Maximum Processing Time** | **Congestion**            | **Challenges**                                                     | **Scalability Issues**           | **Parallelism Needs**             |
|----------------------------|-----------------------------------------|---------------------------|--------------------------------------------------------------------|----------------------------------|----------------------------------|
| **Ethereum**                | ~3-10 seconds                          | **High**                  | Short block time; gas spikes; heavy compute loads                  | Limited throughput               | Critical                          |
| **Bitcoin**    | ~300-1,250 seconds                     | **Low to Medium**          | Long block time; low TPS; slow confirmation times                  | Very slow for smart contracts    | Moderate                         |
| **Fractal**    | ~300-750 seconds                       | **High**                  | Fast block time; needs parallelism to avoid backlogs               | High throughput potential        | Critical                          |
| **Litecoin**   | ~200-500 seconds                       | **Medium**                | Slower block time; moderate TPS; risk of delayed confirmations     | Limited throughput               | High                              |
| **Bellcoin**   | ~300-750 seconds                       | **Medium**                | Block time manageable; parallelism needed for compute-heavy tasks  | High throughput potential        | High                              |

---

## Table 3: OPNet-Enabled Blockchains - Performance With and Without Parallel Processing

| **Blockchain**             | **Theoretical TPS (Without Parallelism)** | **Theoretical TPS (With Parallelism)** | **Processing Time Without Parallelism** | **Processing Time With Parallelism** | **Impact on Congestion Without Parallelism** | **Impact on Congestion With Parallelism**   |
|----------------------------|-------------------------------------------|----------------------------------------|----------------------------------------|-------------------------------------|----------------------------------------------|---------------------------------------------|
| **Bitcoin**    | ~5-10 TPS                                 | ~20-50 TPS                             | ~300-1,250 seconds                    | ~1-120 seconds                     | **Low**, but transactions confirm slowly    | **Moderate**   |
| **Fractal**    | ~100 TPS                                  | ~300-500 TPS                           | ~300-750 seconds                      | ~1-25 seconds                     | **High**, severe backlogs likely            | **Low**      |
| **Litecoin**   | ~13 TPS                                   | ~50-100 TPS                            | ~200-500 seconds                      | ~1-130 seconds                     | **Moderate**, risk of slow confirmations    | **Low**   |
| **Bellcoin**   | ~50 TPS                                   | ~200-400 TPS                           | ~300-750 seconds                      | ~1-45 seconds                     | **Moderate**, congestion in high traffic    | **Low**         |

---

### Explanation of Table 3:

1. **Theoretical TPS (Without/With Parallelism)**: This column shows the theoretical transaction processing speed, comparing blockchains with and without parallel processing.
2. **Processing Time Without/With Parallelism**: This column compares the processing time for a block of OPNet transactions, both with and without parallelism.
3. **Impact on Congestion Without/With Parallelism**: This highlights the expected congestion levels with or without parallelism when handling OPNet's compute-heavy load.

---

## Why Sequential Processing Fails as Transaction Flux Increases

As transaction flux increases, running transactions sequentially creates bottlenecks. On blockchains like Ethereum and Bitcoin, this leads to slower confirmations and higher fees. On faster blockchains like Fractal, the issue is more pronounced because of the short block time (30 seconds), meaning there is even less room to handle high transaction volumes without parallel processing.

---

## How It Works

### 1. Batch Execution of Transactions
- All transactions (txs) in a block are gathered and processed as a batch.
- Each transaction is assumed to be independent at first, allowing concurrent execution across multiple CPU cores.

### 2. State Dependency Identification
- After transactions are processed, the system compares the **state changes** made by each transaction.
- Transactions that modify or rely on the same state (e.g., smart contract data) are marked as **dependent** on each other.
- This creates **chains of dependent transactions** that need to be executed sequentially, as their outcomes depend on the state changes caused by earlier transactions.

### 3. Parallel Execution for Independent Transactions
- Transactions that **do not share state** can be processed in parallel:
  - Example: A swap transaction involving **Banana Token** can run in parallel with a swap involving **Bob Token**, as long as they modify separate states.
- If a transaction does not modify shared state, it can be run across different CPU cores simultaneously, significantly improving execution speed.

### 4. Handling Dependent Transactions
- Transactions that depend on shared states must be executed **sequentially**.
- These transactions are flagged as dependent, forming a **dependency chain**, ensuring the correct order of execution.

### 5. Multithreading for Performance
- By running independent transactions in parallel across multiple CPU cores, **State-Aware Parallelism** reduces block processing time.
- Independent transactions could see up to **1000%** performance improvement, depending on system hardware and the proportion of independent vs. dependent transactions.

### 6. Limitations
- The system cannot parallelize transactions that **share state dependencies**. These must be processed in a specific order, limiting speed improvements for those particular transactions.

---

## Handling Transaction Reverts Due to Missing State

### Why a Transaction May Revert Due to Missing State
In **State-Aware Parallelism**, transactions misclassified as independent may revert if they rely on the state modified by another transaction. When the required state is not available, the dependent transaction reverts. This can cause state inconsistencies and performance degradation due to reprocessing.

### Effects of a Transaction Revert
- **State Integrity**: A reverted transaction indicates an undetected dependency, potentially compromising the systemâ€™s integrity.
- **Execution Order**: Reverts highlight dependencies that should have been sequentially executed.
- **Performance Costs**: Reverts lead to redundant computation, reducing efficiency gains from parallel execution.

### Managing Reverts Due to Missing State

#### 1. Dependency Re-evaluation and Transaction Reclassification
- Upon detecting a revert, the system re-evaluates dependencies and reclassifies affected transactions as dependent. They are then added to the sequential execution queue.

#### 2. Transaction Rollback and Re-execution
- Reverted transactions are rolled back and re-executed after the missing state becomes available, ensuring proper processing.

#### 3. Speculative Execution with Checkpoints
- Transactions can be speculatively executed with **checkpoints**, where the system verifies if a state conflict exists before committing changes. This avoids reverts and wasted computation.

#### 4. Transaction Dependency Prediction Using Heuristics
- Heuristics can be employed to predict transaction dependencies and prevent misclassification, minimizing reverts.

---

## Optimizing Compute with Promises and Context Blocking

### Asynchronous State Availability in Transaction Processing

Using **promises** and **context blocking** in Rust threads, OP_NET can pause the execution of dependent transactions until the required state becomes available, preventing reverts and redundant processing.

### 1. Parallel Execution with Promise-Based State Awaiting
- Independent transactions run in parallel across multiple threads.
- Dependent transactions await state availability using promises:
  - If the required state is unavailable, the transaction is paused using a promise.
  - The system processes other transactions while the paused transaction waits.

### 2. Context Blocking for Dependent Transactions
- Dependent transactions use **context blocking** if they require an unavailable state:
  - The transaction thread is paused without reverting or retrying, minimizing wasted computation.
  - The thread resumes execution once the necessary state is updated.

### 3. Non-Blocking Promises and Resumable Execution
- The system uses **non-blocking promises** to monitor state availability:
  - When the state becomes available, the promise is fulfilled, and the paused transaction resumes from where it left off.

### 4. Sequential and Parallel Scheduling Hybrid
- Independent transactions run in parallel across CPU cores.
- Dependent transactions pause and resume dynamically based on state availability, ensuring optimal compute usage.

### Example Scenario

- **Transaction A** modifies the state of a smart contract.
- **Transaction B**, which depends on the updated state from Transaction A, waits using a promise.
- **Transaction C**, which is independent of both A and B, runs in parallel.
- Once **Transaction A** completes, the promise for **Transaction B** is fulfilled, and **Transaction B** resumes execution without restarting.

---

## Why It Works Like This

1. **State Consistency and Integrity**
   - **State-Aware Parallelism** ensures that transactions modifying or relying on the same state are processed in the correct order. This avoids inconsistencies, such as race conditions or double spending, ensuring that the blockchainâ€™s state remains valid and reliable.
   - By **awaiting state availability**, dependent transactions do not revert or retry. Instead, they are paused until the state they depend on becomes available, which minimizes wasted compute and preserves the blockchainâ€™s integrity.

2. **Concurrency for Performance**
   - OP_NET can safely execute independent transactions in parallel, which significantly reduces block processing time by maximizing the use of available CPU cores. This boosts the systemâ€™s throughput, handling more transactions per block.
   - By allowing dependent transactions to wait on state without reverting, **State-Aware Parallelism** ensures no compute cycles are wasted retrying transactions that would otherwise fail.

3. **Resource Efficiency with Promises and Context Blocking**
   - Using **promises** and **context blocking** allows the system to free up resources while awaiting state changes. This ensures that CPU time is efficiently allocated to transactions that are ready to proceed, while dependent transactions only use resources when they can safely execute.
   - This leads to improved scalability, allowing OP_NET to handle a growing number of transactions while maintaining optimal performance.

4. **Minimized Reverts and Optimized Throughput**
   - Since transactions no longer need to revert when missing a required state, the overall execution flow becomes smoother. Fewer reverts mean less time spent rolling back changes and retrying, leading to better overall throughput and faster block processing.

5. **Scalability**
   - As the number of CPU cores or resources increases, the ability to handle more independent transactions in parallel grows. By ensuring that dependent transactions are processed efficiently and only when they are ready, the system can scale smoothly as network usage increases.

---

## Benefits of This Approach

1. **Avoiding Costly Reverts**: Transactions pause and await state updates rather than reverting, reducing redundant computations.
2. **Optimizing CPU Usage**: Dependent transactions do not consume CPU cycles while waiting, allowing better resource allocation.
3. **Increased Throughput**: The system efficiently handles more transactions by minimizing delays caused by state dependencies.
4. **Smoother Transaction Flow**: Reduced retries and reverts lead to smoother overall block processing.

---

## Key Advantages of **State-Aware Parallelism**

- **Optimized Performance**: Running independent transactions in parallel drastically reduces block processing time.
- **Scalability**: As more CPU cores are available, OP_NET can handle a larger transaction load.
- **State Integrity**: Ensuring dependent transactions are processed sequentially maintains system security and consistency.

---

## Challenges

- **State Dependency Detection**: Efficiently identifying dependencies between transactions is crucial for maximizing parallel execution.
- **Concurrency Handling**: Proper concurrency management is essential to prevent race conditions or state conflicts when running transactions in parallel.

---

## Conclusion

The **State-Aware Parallelism** principle, combined with asynchronous state availability using promises and context blocking, optimizes OP_NETâ€™s transaction throughput by minimizing reverts, reducing redundant processing, and maximizing parallel execution where possible. This ensures OP_NET is both **scalable** and **secure**, allowing for efficient, high-performance transaction processing in a decentralized environment.
